{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e318d9c",
   "metadata": {},
   "source": [
    "# CellLabeller Tutorial: Cell Type Label Transfer\n",
    "\n",
    "This tutorial demonstrates how to use CellLabeller to transfer cell type labels from a reference single-cell dataset to a query dataset using scVI integration and XGBoost classification.\n",
    "\n",
    "## Overview\n",
    "The pipeline consists of the following steps:\n",
    "1. Load reference and query datasets\n",
    "2. Subset datasets to common genes\n",
    "3. Integrate datasets with scVI (â‰¥200 epochs)\n",
    "4. Select features (genes and/or scVI latent space)\n",
    "5. Tune XGBoost hyperparameters (GPU and CPU)\n",
    "6. Train and evaluate models\n",
    "7. Make predictions on query data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4651d4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd447381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the repository to path if needed\n",
    "# sys.path.insert(0, '/path/to/CellLabeller')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization parameters\n",
    "sc.set_figure_params(dpi=100, figsize=(6, 6))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2befc95",
   "metadata": {},
   "source": [
    "## 2. Load Reference and Query Datasets\n",
    "\n",
    "Load your AnnData objects. You can load from various formats:\n",
    "- `.h5ad` files\n",
    "- `.h5` files\n",
    "- `.csv` files (with metadata)\n",
    "- `.loom` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f761e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY THESE PATHS TO YOUR DATA\n",
    "REFERENCE_DATA_PATH = \"path/to/reference_data.h5ad\"  # Replace with your reference data\n",
    "QUERY_DATA_PATH = \"path/to/query_data.h5ad\"  # Replace with your query data\n",
    "RESULTS_DIR = \"./celllabeller_results\"\n",
    "\n",
    "# Load datasets\n",
    "print(\"Loading reference dataset...\")\n",
    "adata_ref = sc.read_h5ad(REFERENCE_DATA_PATH)\n",
    "\n",
    "print(\"Loading query dataset...\")\n",
    "adata_query = sc.read_h5ad(QUERY_DATA_PATH)\n",
    "\n",
    "print(f\"\\nReference dataset shape: {adata_ref.shape}\")\n",
    "print(f\"Query dataset shape: {adata_query.shape}\")\n",
    "\n",
    "# Display cell type distribution in reference\n",
    "CELL_TYPE_KEY = \"cell_type\"  # Modify if your column name is different\n",
    "if CELL_TYPE_KEY in adata_ref.obs:\n",
    "    print(f\"\\nReference cell types:\")\n",
    "    print(adata_ref.obs[CELL_TYPE_KEY].value_counts())\n",
    "    print(f\"\\nTotal cell types: {adata_ref.obs[CELL_TYPE_KEY].nunique()}\")\n",
    "else:\n",
    "    print(f\"Warning: {CELL_TYPE_KEY} not found in reference metadata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432c9c5",
   "metadata": {},
   "source": [
    "## 3. Subset Datasets with Common Genes\n",
    "\n",
    "Ensure both datasets have the same genes for fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2750098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common genes\n",
    "ref_genes = set(adata_ref.var_names)\n",
    "query_genes = set(adata_query.var_names)\n",
    "common_genes = sorted(list(ref_genes.intersection(query_genes)))\n",
    "\n",
    "print(f\"Reference genes: {len(ref_genes)}\")\n",
    "print(f\"Query genes: {len(query_genes)}\")\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "print(f\"Reference genes removed: {len(ref_genes) - len(common_genes)}\")\n",
    "print(f\"Query genes removed: {len(query_genes) - len(common_genes)}\")\n",
    "\n",
    "# Subset to common genes\n",
    "adata_ref = adata_ref[:, common_genes]\n",
    "adata_query = adata_query[:, common_genes]\n",
    "\n",
    "print(f\"\\nNew reference shape: {adata_ref.shape}\")\n",
    "print(f\"New query shape: {adata_query.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45973141",
   "metadata": {},
   "source": [
    "## 4. Integrate Datasets with scVI\n",
    "\n",
    "Concatenate reference and query datasets and integrate using scVI (minimum 200 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c01241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dataset identifier\n",
    "adata_ref.obs[\"dataset\"] = \"reference\"\n",
    "adata_query.obs[\"dataset\"] = \"query\"\n",
    "\n",
    "# Concatenate datasets\n",
    "print(\"Concatenating datasets...\")\n",
    "adata_integrated = ad.concat(\n",
    "    [adata_ref, adata_query],\n",
    "    axis=0,\n",
    "    label=\"dataset_id\",\n",
    "    keys=[\"reference\", \"query\"],\n",
    ")\n",
    "\n",
    "print(f\"Integrated dataset shape: {adata_integrated.shape}\")\n",
    "\n",
    "# Preprocessing\n",
    "print(\"\\nPreprocessing data...\")\n",
    "sc.pp.normalize_total(adata_integrated, target_sum=1e4)\n",
    "sc.pp.log1p(adata_integrated)\n",
    "\n",
    "print(\"âœ“ Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ff272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and train scVI model\n",
    "print(\"Setting up scVI model...\")\n",
    "scvi.model.SCVI.setup_anndata(\n",
    "    adata_integrated,\n",
    "    batch_key=\"dataset\",\n",
    ")\n",
    "\n",
    "# Train scVI (minimum 200 epochs)\n",
    "N_EPOCHS = 250  # At least 200 as required\n",
    "print(f\"\\nTraining scVI model for {N_EPOCHS} epochs...\")\n",
    "print(\"(This may take a few minutes depending on dataset size)\\n\")\n",
    "\n",
    "model_scvi = scvi.model.SCVI(adata_integrated)\n",
    "model_scvi.train(\n",
    "    max_epochs=N_EPOCHS,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"âœ“ scVI training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973efaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latent representation\n",
    "print(\"Extracting scVI latent representation...\")\n",
    "adata_integrated.obsm[\"X_scvi\"] = model_scvi.get_latent_representation()\n",
    "\n",
    "print(f\"Latent space shape: {adata_integrated.obsm['X_scvi'].shape}\")\n",
    "\n",
    "# Save scVI model\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "scvi_model_dir = os.path.join(RESULTS_DIR, \"scvi_model\")\n",
    "print(f\"Saving scVI model to {scvi_model_dir}...\")\n",
    "model_scvi.save(scvi_model_dir, overwrite=True)\n",
    "\n",
    "print(\"âœ“ scVI latent representation extracted and model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7caa55a",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering and Selection\n",
    "\n",
    "Select features based on user preference:\n",
    "- `genes`: Top genes selected by f-score\n",
    "- `scvi_latent`: scVI latent space representation\n",
    "- `combined`: Both genes and latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a126fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Feature selection parameters\n",
    "N_GENES = 500  # Number of top genes to select\n",
    "FEATURE_TYPE = \"combined\"  # Choose: \"genes\", \"scvi_latent\", or \"combined\"\n",
    "\n",
    "print(f\"\\nFeature Selection: {FEATURE_TYPE}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get reference data for feature selection\n",
    "ref_mask = adata_integrated.obs[\"dataset\"] == \"reference\"\n",
    "X_ref = adata_integrated.X[ref_mask]\n",
    "y_ref = adata_integrated.obs.loc[ref_mask, CELL_TYPE_KEY].values\n",
    "\n",
    "print(f\"Reference samples for feature selection: {ref_mask.sum()}\")\n",
    "\n",
    "# Select top genes\n",
    "print(f\"\\nSelecting top {N_GENES} genes...\")\n",
    "selector = SelectKBest(f_classif, k=N_GENES)\n",
    "X_genes_selected = selector.fit_transform(X_ref, y_ref)\n",
    "selected_genes = adata_integrated.var_names[selector.get_support(indices=True)].tolist()\n",
    "\n",
    "print(f\"Selected genes: {len(selected_genes)}\")\n",
    "\n",
    "# Get gene features for full dataset\n",
    "X_genes = adata_integrated[:, selected_genes].X\n",
    "if hasattr(X_genes, 'toarray'):\n",
    "    X_genes = X_genes.toarray()\n",
    "\n",
    "print(f\"Gene feature matrix shape: {X_genes.shape}\")\n",
    "\n",
    "# Get scVI latent features\n",
    "X_scvi = adata_integrated.obsm[\"X_scvi\"]\n",
    "print(f\"scVI latent matrix shape: {X_scvi.shape}\")\n",
    "\n",
    "# Combine features based on user choice\n",
    "if FEATURE_TYPE == \"genes\":\n",
    "    X_features = X_genes\n",
    "    feature_names = selected_genes\n",
    "elif FEATURE_TYPE == \"scvi_latent\":\n",
    "    X_features = X_scvi\n",
    "    feature_names = [f\"scvi_{i}\" for i in range(X_scvi.shape[1])]\n",
    "elif FEATURE_TYPE == \"combined\":\n",
    "    X_features = np.hstack([X_genes, X_scvi])\n",
    "    feature_names = selected_genes + [f\"scvi_{i}\" for i in range(X_scvi.shape[1])]\n",
    "\n",
    "# Standardize features\n",
    "print(f\"\\nStandardizing {len(feature_names)} features...\")\n",
    "scaler = StandardScaler()\n",
    "X_features = scaler.fit_transform(X_features)\n",
    "\n",
    "print(f\"Final feature matrix shape: {X_features.shape}\")\n",
    "print(f\"Feature types: {FEATURE_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99be07",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Testing with XGBoost\n",
    "\n",
    "Conduct hyperparameter tuning using Bayesian optimization (Optuna) for both GPU and CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(adata_integrated.obs[CELL_TYPE_KEY].values)\n",
    "\n",
    "print(f\"Number of cell types: {len(label_encoder.classes_)}\")\n",
    "print(f\"Cell types: {label_encoder.classes_}\")\n",
    "\n",
    "# Split data (80% train, 20% test from reference data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features[ref_mask],\n",
    "    y_encoded[ref_mask],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_encoded[ref_mask],\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "N_TRIALS = 30  # Number of optimization trials (more = longer but better results)\n",
    "\n",
    "def objective_gpu_true(trial):\n",
    "    \"\"\"Objective function for GPU=True\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-5, 10, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-5, 10, log=True),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        clf = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            objective=\"multi:softmax\" if len(label_encoder.classes_) > 2 else \"binary:logistic\",\n",
    "            eval_metric=\"mlogloss\" if len(label_encoder.classes_) > 2 else \"logloss\",\n",
    "            num_class=len(label_encoder.classes_) if len(label_encoder.classes_) > 2 else None,\n",
    "            random_state=42,\n",
    "        )\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"balanced_accuracy\")\n",
    "        return scores.mean()\n",
    "    except Exception as e:\n",
    "        print(f\"GPU trial failed: {e}\")\n",
    "        return float(\"-inf\")\n",
    "\n",
    "def objective_gpu_false(trial):\n",
    "    \"\"\"Objective function for GPU=False\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-5, 10, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-5, 10, log=True),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        clf = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            tree_method=\"hist\",\n",
    "            objective=\"multi:softmax\" if len(label_encoder.classes_) > 2 else \"binary:logistic\",\n",
    "            eval_metric=\"mlogloss\" if len(label_encoder.classes_) > 2 else \"logloss\",\n",
    "            num_class=len(label_encoder.classes_) if len(label_encoder.classes_) > 2 else None,\n",
    "            random_state=42,\n",
    "        )\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=\"balanced_accuracy\")\n",
    "        return scores.mean()\n",
    "    except Exception as e:\n",
    "        print(f\"CPU trial failed: {e}\")\n",
    "        return float(\"-inf\")\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ed9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try GPU tuning (may fail if GPU not available)\n",
    "print(\"\\n[1/2] Tuning with GPU=True...\")\n",
    "try:\n",
    "    sampler_gpu = TPESampler(seed=42)\n",
    "    study_gpu = optuna.create_study(direction=\"maximize\", sampler=sampler_gpu)\n",
    "    study_gpu.optimize(objective_gpu_true, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "    best_params_gpu = study_gpu.best_params\n",
    "    best_score_gpu = study_gpu.best_value\n",
    "    print(f\"âœ“ GPU tuning complete. Best score: {best_score_gpu:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  GPU tuning failed: {e}\")\n",
    "    print(\"  Proceeding with CPU only...\")\n",
    "    best_params_gpu = None\n",
    "    best_score_gpu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU tuning\n",
    "print(\"\\n[2/2] Tuning with GPU=False (CPU)...\")\n",
    "sampler_cpu = TPESampler(seed=42)\n",
    "study_cpu = optuna.create_study(direction=\"maximize\", sampler=sampler_cpu)\n",
    "study_cpu.optimize(objective_gpu_false, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "best_params_cpu = study_cpu.best_params\n",
    "best_score_cpu = study_cpu.best_value\n",
    "print(f\"âœ“ CPU tuning complete. Best score: {best_score_cpu:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Hyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best parameters\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(\"-\"*60)\n",
    "if best_params_gpu is not None:\n",
    "    print(f\"GPU=True (Score: {best_score_gpu:.4f}):\")\n",
    "    for param, value in best_params_gpu.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "else:\n",
    "    print(\"GPU=True: Not available\")\n",
    "\n",
    "print(f\"\\nGPU=False (Score: {best_score_cpu:.4f}):\")\n",
    "for param, value in best_params_cpu.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73c071",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "Train final XGBoost models using the optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f24490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "def train_model_with_params(params, use_gpu=False):\n",
    "    \"\"\"Train XGBoost model with given parameters\"\"\"\n",
    "    training_params = params.copy()\n",
    "    training_params.update({\n",
    "        \"tree_method\": \"gpu_hist\" if use_gpu else \"hist\",\n",
    "        \"gpu_id\": 0 if use_gpu else -1,\n",
    "        \"objective\": \"multi:softmax\" if len(label_encoder.classes_) > 2 else \"binary:logistic\",\n",
    "        \"eval_metric\": \"mlogloss\" if len(label_encoder.classes_) > 2 else \"logloss\",\n",
    "        \"num_class\": len(label_encoder.classes_) if len(label_encoder.classes_) > 2 else None,\n",
    "        \"random_state\": 42,\n",
    "    })\n",
    "    \n",
    "    # Remove None values\n",
    "    training_params = {k: v for k, v in training_params.items() if v is not None}\n",
    "    \n",
    "    model = xgb.XGBClassifier(**training_params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        early_stopping_rounds=10,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Training final models...\\n\")\n",
    "\n",
    "# Train CPU model (always available)\n",
    "print(\"[1/2] Training with CPU...\")\n",
    "model_cpu = train_model_with_params(best_params_cpu, use_gpu=False)\n",
    "print(\"âœ“ CPU model trained\")\n",
    "\n",
    "# Train GPU model if parameters available\n",
    "if best_params_gpu is not None:\n",
    "    print(\"[2/2] Training with GPU...\")\n",
    "    try:\n",
    "        model_gpu = train_model_with_params(best_params_gpu, use_gpu=True)\n",
    "        print(\"âœ“ GPU model trained\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš  GPU model training failed: {e}\")\n",
    "        model_gpu = None\n",
    "else:\n",
    "    model_gpu = None\n",
    "    print(\"[2/2] Skipping GPU model (tuning not completed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e88de",
   "metadata": {},
   "source": [
    "## 8. Score Predictions on Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baecc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, device_name=\"Model\"):\n",
    "    \"\"\"Evaluate model on training and test sets\"\"\"\n",
    "    y_train_pred = model.predict(X_tr)\n",
    "    y_test_pred = model.predict(X_te)\n",
    "    \n",
    "    train_acc = accuracy_score(y_tr, y_train_pred)\n",
    "    test_acc = accuracy_score(y_te, y_test_pred)\n",
    "    \n",
    "    train_bal_acc = balanced_accuracy_score(y_tr, y_train_pred)\n",
    "    test_bal_acc = balanced_accuracy_score(y_te, y_test_pred)\n",
    "    \n",
    "    train_f1 = f1_score(y_tr, y_train_pred, average=\"weighted\", zero_division=0)\n",
    "    test_f1 = f1_score(y_te, y_test_pred, average=\"weighted\", zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{device_name} Performance:\")\n",
    "    print(f\"  Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"  Test Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"  Train Balanced Accuracy: {train_bal_acc:.4f}\")\n",
    "    print(f\"  Test Balanced Accuracy:  {test_bal_acc:.4f}\")\n",
    "    print(f\"  Train F1 (weighted):     {train_f1:.4f}\")\n",
    "    print(f\"  Test F1 (weighted):      {test_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"device\": device_name,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"train_balanced_accuracy\": train_bal_acc,\n",
    "        \"test_balanced_accuracy\": test_bal_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"y_train_pred\": y_train_pred,\n",
    "    }\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_cpu = evaluate_model(model_cpu, X_train, y_train, X_test, y_test, device_name=\"CPU Model\")\n",
    "\n",
    "if model_gpu is not None:\n",
    "    results_gpu = evaluate_model(model_gpu, X_train, y_train, X_test, y_test, device_name=\"GPU Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc79de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED CLASSIFICATION REPORT (CPU)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(\n",
    "    y_test, results_cpu[\"y_test_pred\"],\n",
    "    target_names=label_encoder.classes_.tolist(),\n",
    "    zero_division=0,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee704459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix visualization\n",
    "fig, axes = plt.subplots(1, 1 if model_gpu is None else 2, figsize=(12 if model_gpu is None else 18, 5))\n",
    "\n",
    "if model_gpu is None:\n",
    "    axes = [axes]\n",
    "\n",
    "# CPU confusion matrix\n",
    "cm_cpu = confusion_matrix(y_test, results_cpu[\"y_test_pred\"])\n",
    "sns.heatmap(cm_cpu, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('CPU Model - Confusion Matrix (Test Set)')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "# GPU confusion matrix (if available)\n",
    "if model_gpu is not None:\n",
    "    cm_gpu = confusion_matrix(y_test, results_gpu[\"y_test_pred\"])\n",
    "    sns.heatmap(cm_gpu, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    axes[1].set_title('GPU Model - Confusion Matrix (Test Set)')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrices.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Confusion matrix saved to {RESULTS_DIR}/confusion_matrices.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f306e",
   "metadata": {},
   "source": [
    "## 9. Save Results and Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3eac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(\"Saving models and results...\\n\")\n",
    "\n",
    "# Save CPU model\n",
    "cpu_model_path = os.path.join(RESULTS_DIR, \"xgboost_model_cpu.pkl\")\n",
    "with open(cpu_model_path, \"wb\") as f:\n",
    "    pickle.dump(model_cpu, f)\n",
    "print(f\"âœ“ CPU model saved: {cpu_model_path}\")\n",
    "\n",
    "# Save GPU model if available\n",
    "if model_gpu is not None:\n",
    "    gpu_model_path = os.path.join(RESULTS_DIR, \"xgboost_model_gpu.pkl\")\n",
    "    with open(gpu_model_path, \"wb\") as f:\n",
    "        pickle.dump(model_gpu, f)\n",
    "    print(f\"âœ“ GPU model saved: {gpu_model_path}\")\n",
    "\n",
    "# Save label encoder\n",
    "encoder_path = os.path.join(RESULTS_DIR, \"label_encoder.pkl\")\n",
    "with open(encoder_path, \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f\"âœ“ Label encoder saved: {encoder_path}\")\n",
    "\n",
    "# Save results\n",
    "results_cpu_path = os.path.join(RESULTS_DIR, \"evaluation_results_cpu.pkl\")\n",
    "with open(results_cpu_path, \"wb\") as f:\n",
    "    pickle.dump(results_cpu, f)\n",
    "print(f\"âœ“ CPU results saved: {results_cpu_path}\")\n",
    "\n",
    "if model_gpu is not None:\n",
    "    results_gpu_path = os.path.join(RESULTS_DIR, \"evaluation_results_gpu.pkl\")\n",
    "    with open(results_gpu_path, \"wb\") as f:\n",
    "        pickle.dump(results_gpu, f)\n",
    "    print(f\"âœ“ GPU results saved: {results_gpu_path}\")\n",
    "\n",
    "# Save hyperparameter tuning results\n",
    "tuning_results = {\n",
    "    \"cpu\": {\"best_params\": best_params_cpu, \"best_score\": best_score_cpu},\n",
    "    \"gpu\": {\"best_params\": best_params_gpu, \"best_score\": best_score_gpu} if best_params_gpu else None,\n",
    "}\n",
    "tuning_path = os.path.join(RESULTS_DIR, \"tuning_results.pkl\")\n",
    "with open(tuning_path, \"wb\") as f:\n",
    "    pickle.dump(tuning_results, f)\n",
    "print(f\"âœ“ Tuning results saved: {tuning_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d36003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save integrated data\n",
    "print(\"\\nSaving integrated data...\")\n",
    "integrated_path = os.path.join(RESULTS_DIR, \"integrated_data.h5ad\")\n",
    "adata_integrated.write_h5ad(integrated_path)\n",
    "print(f\"âœ“ Integrated data saved: {integrated_path}\")\n",
    "\n",
    "# Save feature information\n",
    "feature_info = pd.DataFrame({\n",
    "    \"feature_name\": feature_names,\n",
    "    \"feature_type\": [\"gene\"] * len(selected_genes) + [\"scvi\"] * (len(feature_names) - len(selected_genes)),\n",
    "})\n",
    "feature_path = os.path.join(RESULTS_DIR, \"feature_info.csv\")\n",
    "feature_info.to_csv(feature_path, index=False)\n",
    "print(f\"âœ“ Feature information saved: {feature_path}\")\n",
    "\n",
    "print(f\"\\nâœ“ All results saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f610fdfe",
   "metadata": {},
   "source": [
    "## 10. Predict Cell Types for Query Cells\n",
    "\n",
    "Use the trained model to predict cell types for the query dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get query features\n",
    "query_mask = adata_integrated.obs[\"dataset\"] == \"query\"\n",
    "X_query = X_features[query_mask]\n",
    "\n",
    "print(f\"Query samples: {query_mask.sum()}\")\n",
    "print(f\"Query feature matrix shape: {X_query.shape}\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nPredicting cell types for query cells...\")\n",
    "y_query_pred_encoded_cpu = model_cpu.predict(X_query)\n",
    "y_query_pred_cpu = label_encoder.inverse_transform(y_query_pred_encoded_cpu)\n",
    "\n",
    "print(\"Predicted cell type distribution:\")\n",
    "pred_counts = pd.Series(y_query_pred_cpu).value_counts()\n",
    "print(pred_counts)\n",
    "\n",
    "# Get prediction probabilities\n",
    "y_query_proba_cpu = model_cpu.predict_proba(X_query)\n",
    "print(f\"\\nPrediction probabilities shape: {y_query_proba_cpu.shape}\")\n",
    "print(f\"Mean confidence: {y_query_proba_cpu.max(axis=1).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2280b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU predictions (if available)\n",
    "if model_gpu is not None:\n",
    "    print(\"\\nGPU Predictions:\")\n",
    "    y_query_pred_encoded_gpu = model_gpu.predict(X_query)\n",
    "    y_query_pred_gpu = label_encoder.inverse_transform(y_query_pred_encoded_gpu)\n",
    "    \n",
    "    print(\"Predicted cell type distribution:\")\n",
    "    pred_counts_gpu = pd.Series(y_query_pred_gpu).value_counts()\n",
    "    print(pred_counts_gpu)\n",
    "    \n",
    "    # Prediction probabilities\n",
    "    y_query_proba_gpu = model_gpu.predict_proba(X_query)\n",
    "    print(f\"\\nMean confidence: {y_query_proba_gpu.max(axis=1).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de856206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to query AnnData object\n",
    "adata_query.obs[\"predicted_cell_type\"] = y_query_pred_cpu\n",
    "adata_query.obs[\"prediction_confidence\"] = y_query_proba_cpu.max(axis=1)\n",
    "\n",
    "# Add class-specific probabilities\n",
    "for i, cell_type in enumerate(label_encoder.classes_):\n",
    "    adata_query.obs[f\"prob_{cell_type}\"] = y_query_proba_cpu[:, i]\n",
    "\n",
    "print(\"âœ“ Predictions added to query AnnData object\")\n",
    "print(f\"\\nColumns in query data: {list(adata_query.obs.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b257826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted query data\n",
    "query_pred_path = os.path.join(RESULTS_DIR, \"query_with_predictions.h5ad\")\n",
    "adata_query.write_h5ad(query_pred_path)\n",
    "print(f\"âœ“ Query data with predictions saved: {query_pred_path}\")\n",
    "\n",
    "# Save predictions as CSV\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"cell_id\": adata_query.obs_names,\n",
    "    \"predicted_cell_type\": y_query_pred_cpu,\n",
    "    \"confidence\": y_query_proba_cpu.max(axis=1),\n",
    "})\n",
    "for i, cell_type in enumerate(label_encoder.classes_):\n",
    "    predictions_df[f\"prob_{cell_type}\"] = y_query_proba_cpu[:, i]\n",
    "\n",
    "predictions_csv_path = os.path.join(RESULTS_DIR, \"query_predictions.csv\")\n",
    "predictions_df.to_csv(predictions_csv_path, index=False)\n",
    "print(f\"âœ“ Predictions saved as CSV: {predictions_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a0062",
   "metadata": {},
   "source": [
    "## Summary and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53acd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "summary_report = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           CELLLABELLER ANALYSIS SUMMARY REPORT                 â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ðŸ“Š DATASET INFORMATION\n",
    "{'â”€'*62}\n",
    "  Reference dataset shape:        {adata_ref.shape}\n",
    "  Query dataset shape:            {adata_query.shape}\n",
    "  Common genes:                   {len(common_genes)}\n",
    "  Integration method:             scVI\n",
    "  scVI epochs:                    {N_EPOCHS}\n",
    "\n",
    "ðŸ”§ FEATURE ENGINEERING\n",
    "{'â”€'*62}\n",
    "  Feature type:                   {FEATURE_TYPE}\n",
    "  Total features:                 {len(feature_names)}\n",
    "  Gene features:                  {len(selected_genes)}\n",
    "  scVI latent components:         {X_scvi.shape[1]}\n",
    "\n",
    "ðŸŽ¯ MODEL TRAINING\n",
    "{'â”€'*62}\n",
    "  Training samples:               {X_train.shape[0]}\n",
    "  Test samples:                   {X_test.shape[0]}\n",
    "  Number of cell types:           {len(label_encoder.classes_)}\n",
    "  Cell types:                     {', '.join(label_encoder.classes_)}\n",
    "\n",
    "ðŸ“ˆ CPU MODEL PERFORMANCE\n",
    "{'â”€'*62}\n",
    "  Train Accuracy:                 {results_cpu['train_accuracy']:.4f}\n",
    "  Test Accuracy:                  {results_cpu['test_accuracy']:.4f}\n",
    "  Train Balanced Accuracy:        {results_cpu['train_balanced_accuracy']:.4f}\n",
    "  Test Balanced Accuracy:         {results_cpu['test_balanced_accuracy']:.4f}\n",
    "  Train F1 (weighted):            {results_cpu['train_f1']:.4f}\n",
    "  Test F1 (weighted):             {results_cpu['test_f1']:.4f}\n",
    "\n",
    "ðŸ’¾ RESULTS DIRECTORY\n",
    "{'â”€'*62}\n",
    "  Location:                       {RESULTS_DIR}\n",
    "  Models:                         âœ“\n",
    "  Tuning results:                 âœ“\n",
    "  Integrated data:                âœ“\n",
    "  Predictions:                    âœ“\n",
    "\n",
    "âœ… ANALYSIS COMPLETE\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save report\n",
    "report_path = os.path.join(RESULTS_DIR, \"ANALYSIS_REPORT.txt\")\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(summary_report)\n",
    "print(f\"Report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Reference cell type distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "adata_ref.obs[CELL_TYPE_KEY].value_counts().plot(kind='barh', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Reference Cell Type Distribution', fontweight='bold')\n",
    "ax1.set_xlabel('Count')\n",
    "\n",
    "# 2. Query predicted cell type distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "pd.Series(y_query_pred_cpu).value_counts()[label_encoder.classes_].plot(kind='barh', ax=ax2, color='darkgreen')\n",
    "ax2.set_title('Query Predicted Cell Type Distribution', fontweight='bold')\n",
    "ax2.set_xlabel('Count')\n",
    "\n",
    "# 3. Model performance comparison\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "metrics = ['Train Acc', 'Test Acc', 'Train Bal Acc', 'Test Bal Acc']\n",
    "values = [\n",
    "    results_cpu['train_accuracy'],\n",
    "    results_cpu['test_accuracy'],\n",
    "    results_cpu['train_balanced_accuracy'],\n",
    "    results_cpu['test_balanced_accuracy'],\n",
    "]\n",
    "ax3.bar(metrics, values, color='steelblue', alpha=0.8)\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('CPU Model Performance Metrics', fontweight='bold')\n",
    "ax3.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random')\n",
    "for i, v in enumerate(values):\n",
    "    ax3.text(i, v + 0.02, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Prediction confidence distribution\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax4.hist(y_query_proba_cpu.max(axis=1), bins=30, color='darkgreen', alpha=0.7, edgecolor='black')\n",
    "ax4.set_xlabel('Prediction Confidence')\n",
    "ax4.set_ylabel('Number of Cells')\n",
    "ax4.set_title(f'Query Prediction Confidence\\n(Mean: {y_query_proba_cpu.max(axis=1).mean():.4f})', fontweight='bold')\n",
    "\n",
    "# 5. Feature contribution (top 20 genes if available)\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "if len(selected_genes) > 0:\n",
    "    feature_importance = model_cpu.feature_importances_[:len(selected_genes)]\n",
    "    top_features_idx = np.argsort(feature_importance)[-20:]\n",
    "    top_genes = np.array(selected_genes)[top_features_idx]\n",
    "    top_importance = feature_importance[top_features_idx]\n",
    "    \n",
    "    y_pos = np.arange(len(top_genes))\n",
    "    ax5.barh(y_pos, top_importance, color='coral', alpha=0.8)\n",
    "    ax5.set_yticks(y_pos)\n",
    "    ax5.set_yticklabels(top_genes, fontsize=9)\n",
    "    ax5.set_xlabel('Feature Importance')\n",
    "    ax5.set_title('Top 20 Most Important Genes', fontweight='bold')\n",
    "    ax5.invert_yaxis()\n",
    "\n",
    "plt.savefig(os.path.join(RESULTS_DIR, 'analysis_summary.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Summary visualization saved to {RESULTS_DIR}/analysis_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e9571",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Your cell type label transfer analysis is complete! Here's what you can do next:\n",
    "\n",
    "### 1. **Validate Predictions**\n",
    "   - Compare predicted labels with any existing annotations in your query data\n",
    "   - Check prediction confidence scores (look for low-confidence predictions)\n",
    "   - Investigate cells with conflicting predictions between GPU/CPU models\n",
    "\n",
    "### 2. **Explore Results**\n",
    "   - Review confusion matrices to identify which cell types are commonly misclassified\n",
    "   - Examine feature importance to understand which genes drive the classification\n",
    "   - Analyze prediction probabilities for uncertain cells\n",
    "\n",
    "### 3. **Refine the Model**\n",
    "   - Adjust hyperparameters if needed (increase `N_TRIALS` for more thorough search)\n",
    "   - Try different feature combinations (`FEATURE_TYPE`)\n",
    "   - Increase scVI epochs for better integration (`N_EPOCHS`)\n",
    "\n",
    "### 4. **Use the Trained Model**\n",
    "   - Load the saved model to predict labels for new query datasets\n",
    "   - See the CellLabeller documentation for production usage examples\n",
    "\n",
    "### 5. **Visualization**\n",
    "   - Create UMAP/t-SNE plots with predicted labels\n",
    "   - Visualize feature importance and prediction confidence\n",
    "   - Generate publication-quality figures\n",
    "\n",
    "### Useful Commands for Loading and Using Models\n",
    "```python\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load saved model and encoder\n",
    "with open('celllabeller_results/xgboost_model_cpu.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('celllabeller_results/label_encoder.pkl', 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "# Make predictions on new features\n",
    "y_pred_encoded = model.predict(new_features)\n",
    "y_pred_labels = encoder.inverse_transform(y_pred_encoded)\n",
    "y_proba = model.predict_proba(new_features)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
